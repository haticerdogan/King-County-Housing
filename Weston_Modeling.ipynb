{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Notebook \n",
    "\n",
    "Creating a model to best predict housing prices for a real estate agency.\n",
    "\n",
    "The function for the model gives the option of a statsmodel summary and a test visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages, libraries, functions and variables from the EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the needed packages, libraries, functions and variables from the EDA notebook.\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original DataFrame\n",
    "%store -r df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaned DataFrame â€” from the EDA notebook\n",
    "%store -r df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For consistent randomness\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model needs to have only numeric variables.\n",
    "# Using this function, we can drop all columns without numeric varibales.\n",
    "# We will input this function within our next function.\n",
    "def only_numeric(data):\n",
    "    '''returns a dataframe with only numeric values'''\n",
    "    for column in data.columns:\n",
    "        if is_numeric_dtype(data[column]) == False:\n",
    "            data = data.drop(column, axis=1)\n",
    "        else:\n",
    "            continue\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns our y and X for any data frame. \n",
    "# Uses all the numeric columns, need to pass a string as a target variable.\n",
    "def get_y_X(data, target):\n",
    "    data = only_numeric(data) # Making data only columns with numeric values.\n",
    "    y = data[target] \n",
    "    X = data.drop(target, axis=1)\n",
    "    return y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return a train / test split variables for an X and y. \n",
    "def my_train_test(ys, Xs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size=.2)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prediction function is not in effect, work in progress. \n",
    "def prediction(ys, Xs):\n",
    "    y_hat = lr.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_hat))\n",
    "    return rmse, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare R2 values and RMSE values of the train and testing models\n",
    "def train_test_compare(X_tr, X_te, y_tr, y_te):\n",
    "    model = lr.fit(X_tr, y_tr) # fit the model\n",
    "    \n",
    "    #R2 Scores\n",
    "    train_score = lr.score(X_tr, y_tr)\n",
    "    test_score = lr.score(X_te, y_te)\n",
    "    \n",
    "    #RMSE\n",
    "    y_hat_train = lr.predict(X_tr)\n",
    "    y_hat_test = lr.predict(X_te)\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_tr, y_hat_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_te, y_hat_test))\n",
    "    \n",
    "    print(f' training data R2: {train_score}\\n testing data R2: {test_score} \\\n",
    "                    \\n training data rmse: {train_rmse}\\n testing data rmse: {test_rmse}')\n",
    "    \n",
    "    #stats model\n",
    "    stats_summ = input('Do you want a statsmodel summary? (y/n)')\n",
    "    if stats_summ == 'y':\n",
    "        inter = model.intercept_\n",
    "        stats = sm.OLS(y_tr, sm.add_constant(X_tr)).fit()\n",
    "        summary = stats.summary()\n",
    "        print(summary)\n",
    "        \n",
    "    # visualization\n",
    "    viz = input('Do you want a viz of the test? (y/n)')\n",
    "    if viz == 'y':\n",
    "        preds = model.predict(X_te)\n",
    "        fig, ax = plt.subplots()\n",
    "        perfect_line = np.arange(y_test.min(), y_test.max())\n",
    "        ax.plot(perfect_line, linestyle=\"--\", color=\"orange\", label='regression line')\n",
    "        ax.scatter(y_test, preds, alpha=0.5)\n",
    "        ax.set_xlabel(\"Predictors\")\n",
    "        ax.set_ylabel(\"Predicted Price\")\n",
    "        ax.legend();\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am not sure if I am doing the RMSE correctly, but I am pretty confident with the R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using test data to demonstrate\n",
    "test_data = df_clean.loc[:,['price', 'bedrooms', 'condition', 'sqft_living']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training data R2: 0.5231126196574214\n",
      " testing data R2: 0.4724396980832275                     \n",
      " training data rmse: 257532.38330153355\n",
      " testing data rmse: 249942.04629419878\n",
      "Do you want a statsmodel summary? (y/n)\n",
      "Do you want a viz of the test? (y/n)\n"
     ]
    }
   ],
   "source": [
    "y, X = get_y_X(test_data, 'price')\n",
    "\n",
    "X_train, X_test, y_train, y_test = my_train_test(y, X)\n",
    "\n",
    "train_test_compare(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model on with Entire Clean DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training data R2: 0.6616112498182487\n",
      " testing data R2: 0.6663057291310652                     \n",
      " training data rmse: 212947.1093118701\n",
      " testing data rmse: 215160.1924757349\n",
      "Do you want a statsmodel summary? (y/n)\n",
      "Do you want a viz of the test? (y/n)\n"
     ]
    }
   ],
   "source": [
    "y, X = get_y_X(df_clean, 'price')\n",
    "X_train, X_test, y_train, y_test = my_train_test(y, X)\n",
    "train_test_compare(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Dummy Variables for Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_dumm = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummies\n",
    "zipcode_dummies = pd.get_dummies(df_clean_dumm['zipcode'], drop_first=True)\n",
    "waterfront_dummies = pd.get_dummies(df_clean_dumm['waterfront'], drop_first=True)\n",
    "view_dummies = pd.get_dummies(df_clean_dumm['view'], drop_first=True)\n",
    "month_dummies = pd.get_dummies(df_clean_dumm['month'], drop_first=True)\n",
    "\n",
    "df_clean_dumm = pd.concat([df_clean_dumm, waterfront_dummies, \n",
    "                           view_dummies, month_dummies, zipcode_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training data R2: 0.8045709270072421\n",
      " testing data R2: 0.8128858586897085                     \n",
      " training data rmse: 162808.7557475854\n",
      " testing data rmse: 157282.84300251346\n",
      "Do you want a statsmodel summary? (y/n)\n",
      "Do you want a viz of the test? (y/n)\n"
     ]
    }
   ],
   "source": [
    "y, X = get_y_X(df_clean_dumm, 'price')\n",
    "X_train, X_test, y_train, y_test = my_train_test(y, X)\n",
    "train_test_compare(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with non-Luxury houses w/ Dummy Variabls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_lux = df_clean_dumm.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_lux = non_lux[non_lux['price'] < 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training data R2: 0.8324379377688897\n",
      " testing data R2: 0.8213755034562888                     \n",
      " training data rmse: 79936.96310619239\n",
      " testing data rmse: 82982.95208673915\n",
      "Do you want a statsmodel summary? (y/n)\n",
      "Do you want a viz of the test? (y/n)\n"
     ]
    }
   ],
   "source": [
    "y, X = get_y_X(non_lux, 'price')\n",
    "X_train, X_test, y_train, y_test = my_train_test(y, X)\n",
    "train_test_compare(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with non-Luxury and non-Cheap houses w/ Dummy Variabls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_lux_cheap = non_lux.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_lux_cheap = no_lux_cheap[no_lux_cheap['price'] > 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training data R2: 0.8303860053880922\n",
      " testing data R2: 0.8250601018040645                     \n",
      " training data rmse: 80300.42116759688\n",
      " testing data rmse: 81802.15603649514\n",
      "Do you want a statsmodel summary? (y/n)\n",
      "Do you want a viz of the test? (y/n)\n"
     ]
    }
   ],
   "source": [
    "y, X = get_y_X(no_lux_cheap, 'price')\n",
    "X_train, X_test, y_train, y_test = my_train_test(y, X)\n",
    "train_test_compare(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with non-Luxury houses w/ Dummy Variables - drop recurring columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_lux_drop = non_lux.copy()\n",
    "non_lux_drop = non_lux_drop.drop(['lat', 'long', 'sqft_lot15', 'month', 'waterfront', 'zipcode', 'view'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training data R2: 0.8287404311570663\n",
      " testing data R2: 0.8347545522224356                     \n",
      " training data rmse: 80643.85597282492\n",
      " testing data rmse: 80478.00466188866\n",
      "Do you want a statsmodel summary? (y/n)\n",
      "Do you want a viz of the test? (y/n)\n"
     ]
    }
   ],
   "source": [
    "y, X = get_y_X(non_lux_drop, 'price')\n",
    "X_train, X_test, y_train, y_test = my_train_test(y, X)\n",
    "train_test_compare(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0033c84df5fb4c613acf884834f63930b25da6784759ce0fb831a430fcd673895"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
